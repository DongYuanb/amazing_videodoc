#!/usr/bin/env python3
"""
å›¾æ–‡æ··æ’ç¬”è®°ç”Ÿæˆå™¨ - å°†è§†é¢‘è½¬æ¢ä¸ºç»“æ„åŒ–çš„å›¾æ–‡ç¬”è®°
æ”¯æŒå¤šç§å¯¼å‡ºæ ¼å¼ï¼šJSONã€Markdownã€HTML
"""
import os
import logging
import json
from pathlib import Path
import concurrent.futures
import threading
from typing import List, Dict, Any, Optional
from datetime import datetime
from video_frame_deduplicator import VideoFrameDeduplicator

class MultimodalNoteGenerator:
    """å›¾æ–‡æ··æ’ç¬”è®°ç”Ÿæˆå™¨"""
    
    def __init__(self,
                 cohere_api_key: str,
                 ffmpeg_path: str = "ffmpeg",
                 frame_fps: float = 0.1,  # æ¯10ç§’æŠ½ä¸€å¸§
                 similarity_threshold: float = 0.9,
                 max_concurrent_segments: int = 3,
                 logger: Optional[logging.Logger] = None):
        """
        åˆå§‹åŒ–å›¾æ–‡ç¬”è®°ç”Ÿæˆå™¨

        Args:
            cohere_api_key: Cohere APIå¯†é’¥ï¼ˆç”¨äºå›¾ç‰‡å»é‡ï¼‰
            ffmpeg_path: ffmpegè·¯å¾„
            frame_fps: æŠ½å¸§é¢‘ç‡ï¼ˆæ¯ç§’å¸§æ•°ï¼‰
            similarity_threshold: å›¾ç‰‡ç›¸ä¼¼åº¦é˜ˆå€¼
            max_concurrent_segments: æœ€å¤§å¹¶å‘å¤„ç†çš„æ—¶é—´æ®µæ•°é‡
            logger: æ—¥å¿—è®°å½•å™¨
        """
        if not cohere_api_key:
            raise ValueError("COHERE_API_KEY ä¸èƒ½ä¸ºç©º")

        self.logger = logger or logging.getLogger(__name__)
        self.frame_fps = frame_fps
        self.max_concurrent_segments = max_concurrent_segments
        self._embedding_lock = threading.Lock()

        try:
            self.frame_deduplicator = VideoFrameDeduplicator(
                cohere_api_key=cohere_api_key,
                ffmpeg_path=ffmpeg_path,
                similarity_threshold=similarity_threshold,
                logger=self.logger
            )
        except Exception as e:
            self.logger.error(f"VideoFrameDeduplicator åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _parse_time_to_seconds(self, time_str: str) -> float:
        """å°†æ—¶é—´å­—ç¬¦ä¸²(HH:MM:SS.mmm)è½¬æ¢ä¸ºç§’æ•°"""
        try:
            # è§£æ HH:MM:SS.mmm æ ¼å¼
            time_parts = time_str.split(':')
            hours = int(time_parts[0])
            minutes = int(time_parts[1])
            seconds_parts = time_parts[2].split('.')
            seconds = int(seconds_parts[0])
            milliseconds = int(seconds_parts[1]) if len(seconds_parts) > 1 else 0
            
            total_seconds = hours * 3600 + minutes * 60 + seconds + milliseconds / 1000
            return total_seconds
        except (ValueError, IndexError) as e:
            raise ValueError(f"æ— æ³•è§£ææ—¶é—´æ ¼å¼: {time_str}, é”™è¯¯: {e}")
    
    def extract_segment_frames(self, video_path: str, start_time: str,
                              end_time: str, output_dir: str) -> List[str]:
        """æå–æŒ‡å®šæ—¶é—´æ®µçš„è§†é¢‘å¸§å¹¶å»é‡"""
        start_seconds = self._parse_time_to_seconds(start_time)
        end_seconds = self._parse_time_to_seconds(end_time)

        segment_dir = os.path.join(output_dir, f"segment_{start_time.replace(':', '-')}_to_{end_time.replace(':', '-')}")
        os.makedirs(segment_dir, exist_ok=True)

        try:
            result = self.frame_deduplicator.process_video_frames(
                video_path=video_path,
                start_time=start_seconds,
                end_time=end_seconds,
                output_dir=segment_dir,
                fps=self.frame_fps,
                keep_temp_files=False,
                embedding_lock=self._embedding_lock
            )
            return result.get("saved_paths", [])
        except Exception as e:
            self.logger.error(f"æ—¶é—´æ®µ {start_time}-{end_time} å¸§å¤„ç†å¤±è´¥: {e}")
            return []

    def _process_single_segment(self, segment_data: tuple) -> dict:
        """å¤„ç†å•ä¸ªæ—¶é—´æ®µçš„å¸§æå–"""
        i, segment, video_path, frames_dir, output_dir = segment_data
        start_time = segment.get("start_time", "")
        end_time = segment.get("end_time", "")
        summary = segment.get("summary", "")

        try:
            frame_paths = self.extract_segment_frames(video_path, start_time, end_time, frames_dir)
            relative_frame_paths = [os.path.relpath(path, output_dir) for path in frame_paths]
        except Exception as e:
            self.logger.error(f"æ—¶é—´æ®µ {start_time}-{end_time} å¸§æå–å¤±è´¥: {e}")
            relative_frame_paths = []

        return {
            "segment_id": i + 1,
            "start_time": start_time,
            "end_time": end_time,
            "duration_seconds": self._parse_time_to_seconds(end_time) - self._parse_time_to_seconds(start_time),
            "summary": summary,
            "key_frames": relative_frame_paths,
            "frame_count": len(relative_frame_paths)
        }
    
    def generate_multimodal_notes(self,
                                 video_path: str,
                                 summary_json_path: str,
                                 output_dir: str) -> str:
        """
        ç”Ÿæˆå›¾æ–‡æ··æ’ç¬”è®°ï¼ˆæ”¯æŒæ—¶é—´æ®µçº§åˆ«å¹¶å‘å¤„ç†ï¼‰

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            summary_json_path: æ‘˜è¦JSONæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            ç”Ÿæˆçš„å›¾æ–‡ç¬”è®°JSONæ–‡ä»¶è·¯å¾„
        """
        # è¯»å–æ‘˜è¦æ•°æ®
        with open(summary_json_path, 'r', encoding='utf-8') as f:
            summary_data = json.load(f)

        summaries = summary_data.get("summaries", [])
        if not summaries:
            raise ValueError("æ‘˜è¦æ•°æ®ä¸ºç©º")

        os.makedirs(output_dir, exist_ok=True)
        frames_dir = os.path.join(output_dir, "frames")
        os.makedirs(frames_dir, exist_ok=True)

        segment_tasks = [(i, segment, video_path, frames_dir, output_dir)
                        for i, segment in enumerate(summaries)]

        multimodal_notes = []
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_concurrent_segments) as executor:
            future_to_index = {executor.submit(self._process_single_segment, task_data): task_data[0]
                              for task_data in segment_tasks}

            results = {}
            for future in concurrent.futures.as_completed(future_to_index):
                index = future_to_index[future]
                try:
                    results[index] = future.result()
                except Exception as e:
                    self.logger.error(f"æ—¶é—´æ®µ {index+1} å¤„ç†å¤±è´¥: {e}")
                    segment = summaries[index]
                    results[index] = {
                        "segment_id": index + 1,
                        "start_time": segment.get("start_time", ""),
                        "end_time": segment.get("end_time", ""),
                        "duration_seconds": 0,
                        "summary": segment.get("summary", ""),
                        "key_frames": [],
                        "frame_count": 0
                    }

            for i in range(len(summaries)):
                if i in results:
                    multimodal_notes.append(results[i])

        final_notes = {
            "video_info": {
                "source_video": os.path.basename(video_path),
                "total_segments": len(multimodal_notes),
                "generated_at": datetime.now().isoformat(),
                "processing_mode": f"concurrent (max_workers={self.max_concurrent_segments})"
            },
            "segments": multimodal_notes,
            "statistics": {
                "total_frames": sum(note["frame_count"] for note in multimodal_notes),
                "segments_with_frames": len([note for note in multimodal_notes if note["frame_count"] > 0])
            }
        }

        output_file = os.path.join(output_dir, "multimodal_notes.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_notes, f, ensure_ascii=False, indent=4)

        return output_file

    def export_to_markdown(self, notes_json_path: str, output_path: str = None,
                          image_base_path: str = None) -> str:
        """å°†å›¾æ–‡ç¬”è®°å¯¼å‡ºä¸º Markdown æ ¼å¼"""
        with open(notes_json_path, 'r', encoding='utf-8') as f:
            notes_data = json.load(f)

        if output_path is None:
            output_path = f"{Path(notes_json_path).stem}.md"
        if image_base_path is None:
            image_base_path = str(Path(notes_json_path).parent)

        markdown_content = self._generate_markdown_content(notes_data, output_path, image_base_path)

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)

        return output_path


    def _generate_markdown_content(self, notes_data: Dict[str, Any],
                                  output_path: str = None,
                                  image_base_path: str = None) -> str:
        """ç”Ÿæˆ Markdown å†…å®¹"""
        video_info = notes_data.get("video_info", {})
        segments = notes_data.get("segments", [])
        statistics = notes_data.get("statistics", {})

        # æ„å»º Markdown
        lines = []

        # æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
        lines.append(f"# ğŸ“¹ è§†é¢‘ç¬”è®°ï¼š{video_info.get('source_video', 'æœªçŸ¥è§†é¢‘')}")
        lines.append("")
        lines.append("## ğŸ“Š åŸºæœ¬ä¿¡æ¯")
        lines.append("")
        lines.append(f"- **è§†é¢‘æ–‡ä»¶**: {video_info.get('source_video', 'æœªçŸ¥')}")
        lines.append(f"- **ç”Ÿæˆæ—¶é—´**: {video_info.get('generated_at', 'æœªçŸ¥')}")
        lines.append(f"- **æ€»æ—¶é—´æ®µ**: {video_info.get('total_segments', 0)}")
        lines.append(f"- **æ€»å…³é”®å¸§**: {statistics.get('total_frames', 0)}")
        lines.append(f"- **æœ‰æ•ˆæ—¶é—´æ®µ**: {statistics.get('segments_with_frames', 0)}")
        lines.append("")

        # ç›®å½•
        lines.append("## ğŸ“‘ ç›®å½•")
        lines.append("")
        for i, segment in enumerate(segments, 1):
            start_time = segment.get("start_time", "")
            end_time = segment.get("end_time", "")
            lines.append(f"{i}. [{start_time} - {end_time}](#æ—¶é—´æ®µ-{i})")
        lines.append("")

        # è¯¦ç»†å†…å®¹
        lines.append("## ğŸ“ è¯¦ç»†å†…å®¹")
        lines.append("")

        for i, segment in enumerate(segments, 1):
            start_time = segment.get("start_time", "")
            end_time = segment.get("end_time", "")
            duration = segment.get("duration_seconds", 0)
            summary = segment.get("summary", "")
            key_frames = segment.get("key_frames", [])

            # æ—¶é—´æ®µæ ‡é¢˜
            lines.append(f"### æ—¶é—´æ®µ {i}")
            lines.append("")
            lines.append(f"**â° æ—¶é—´**: {start_time} - {end_time} ({duration:.1f}ç§’)")
            lines.append("")

            # æ‘˜è¦å†…å®¹
            lines.append("**ğŸ“‹ æ‘˜è¦**:")
            lines.append("")
            lines.append(summary)
            lines.append("")

            # å…³é”®å¸§
            if key_frames:
                lines.append(f"**ğŸ–¼ï¸ å…³é”®å¸§** ({len(key_frames)}å¼ ):")
                lines.append("")
                for frame_path in key_frames:
                    frame_name = Path(frame_path).name

                    # ç›´æ¥æ‹¼æ¥æ­£ç¡®çš„è·¯å¾„ï¼š/storage/tasks/{task_id}/multimodal_notes/frames/segment_xxx/unique_frame_xxx.jpg
                    if image_base_path:
                        # image_base_path æ˜¯ task_dirï¼Œå³ /storage/tasks/{task_id}
                        image_path = f"/{image_base_path}/multimodal_notes/{frame_path}"
                    else:
                        # å¤‡ç”¨æ–¹æ¡ˆ
                        image_path = f"multimodal_notes/{frame_path}"

                    lines.append(f"![{frame_name}]({image_path})")
                lines.append("")
            else:
                lines.append("*è¯¥æ—¶é—´æ®µæ— å…³é”®å¸§*")
                lines.append("")

            lines.append("---")
            lines.append("")

        # é¡µè„š
        lines.append("## ğŸ”§ ç”Ÿæˆä¿¡æ¯")
        lines.append("")
        lines.append("æœ¬ç¬”è®°ç”±è§†é¢‘å¤„ç† API è‡ªåŠ¨ç”Ÿæˆ")
        lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        if output_path:
            lines.append(f"è¾“å‡ºæ–‡ä»¶: {output_path}")

        return "\n".join(lines)



def generate_video_notes(video_path: str, summary_json_path: str, output_dir: str,
                        cohere_api_key: str, frame_fps: float = 0.1,
                        max_concurrent_segments: int = 3,
                        logger: Optional[logging.Logger] = None) -> str:
    """ç”Ÿæˆè§†é¢‘çš„å›¾æ–‡æ··æ’ç¬”è®°"""
    generator = MultimodalNoteGenerator(
        cohere_api_key=cohere_api_key,
        frame_fps=frame_fps,
        max_concurrent_segments=max_concurrent_segments,
        logger=logger
    )
    return generator.generate_multimodal_notes(video_path, summary_json_path, output_dir)


