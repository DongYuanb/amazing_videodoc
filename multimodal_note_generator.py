#!/usr/bin/env python3
"""
å›¾æ–‡æ··æ’ç¬”è®°ç”Ÿæˆå™¨ - å°†è§†é¢‘è½¬æ¢ä¸ºç»“æ„åŒ–çš„å›¾æ–‡ç¬”è®°
æ”¯æŒå¤šç§å¯¼å‡ºæ ¼å¼ï¼šJSONã€Markdownã€HTML
"""
import os
import logging
import json
from pathlib import Path
import concurrent.futures
import threading
from typing import List, Dict, Any, Optional
from datetime import datetime
from video_frame_deduplicator import VideoFrameDeduplicator
from dotenv import load_dotenv
load_dotenv()

cohere_api_key = os.getenv("COHERE_API_KEY")

class MultimodalNoteGenerator:
    """å›¾æ–‡æ··æ’ç¬”è®°ç”Ÿæˆå™¨"""
    
    def __init__(self,
                 cohere_api_key: str,
                 ffmpeg_path: str = "ffmpeg",
                 frame_fps: float = 0.5,  # æ¯2ç§’æŠ½ä¸€å¸§
                 similarity_threshold: float = 0.9,
                 max_concurrent_segments: int = 3,
                 logger: Optional[logging.Logger] = None):
        """
        åˆå§‹åŒ–å›¾æ–‡ç¬”è®°ç”Ÿæˆå™¨

        Args:
            cohere_api_key: Cohere APIå¯†é’¥ï¼ˆç”¨äºå›¾ç‰‡å»é‡ï¼‰
            ffmpeg_path: ffmpegè·¯å¾„
            frame_fps: æŠ½å¸§é¢‘ç‡ï¼ˆæ¯ç§’å¸§æ•°ï¼‰
            similarity_threshold: å›¾ç‰‡ç›¸ä¼¼åº¦é˜ˆå€¼
            max_concurrent_segments: æœ€å¤§å¹¶å‘å¤„ç†çš„æ—¶é—´æ®µæ•°é‡
            logger: æ—¥å¿—è®°å½•å™¨
        """
        if not cohere_api_key:
            raise ValueError("COHERE_API_KEY ä¸èƒ½ä¸ºç©º")

        self.logger = logger or logging.getLogger(__name__)

        self.logger.info("ğŸ”§ åˆå§‹åŒ–å›¾æ–‡ç¬”è®°ç”Ÿæˆå™¨...")
        self.logger.info(f"   - Cohere API Key: {'å·²è®¾ç½®' if cohere_api_key else 'æœªè®¾ç½®'}")
        self.logger.info(f"   - FFmpegè·¯å¾„: {ffmpeg_path}")
        self.logger.info(f"   - æŠ½å¸§é¢‘ç‡: {frame_fps} fps")

        try:
            self.frame_deduplicator = VideoFrameDeduplicator(
                cohere_api_key=cohere_api_key,
                ffmpeg_path=ffmpeg_path,
                similarity_threshold=similarity_threshold,
                logger=self.logger
            )
            self.frame_fps = frame_fps
            self.max_concurrent_segments = max_concurrent_segments
            # ç”¨äºä¿æŠ¤embedding APIè°ƒç”¨çš„é”ï¼ˆç¡®ä¿embeddingé˜¶æ®µä¸²è¡Œï¼‰
            self._embedding_lock = threading.Lock()
            self.logger.info("âœ… å›¾æ–‡ç¬”è®°ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"âŒ VideoFrameDeduplicator åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _parse_time_to_seconds(self, time_str: str) -> float:
        """
        å°†æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºç§’æ•°
        
        Args:
            time_str: æ—¶é—´å­—ç¬¦ä¸²ï¼Œæ ¼å¼å¦‚ "00:14:31.180"
            
        Returns:
            ç§’æ•°ï¼ˆæµ®ç‚¹æ•°ï¼‰
        """
        try:
            # è§£æ HH:MM:SS.mmm æ ¼å¼
            time_parts = time_str.split(':')
            hours = int(time_parts[0])
            minutes = int(time_parts[1])
            seconds_parts = time_parts[2].split('.')
            seconds = int(seconds_parts[0])
            milliseconds = int(seconds_parts[1]) if len(seconds_parts) > 1 else 0
            
            total_seconds = hours * 3600 + minutes * 60 + seconds + milliseconds / 1000
            return total_seconds
        except (ValueError, IndexError) as e:
            raise ValueError(f"æ— æ³•è§£ææ—¶é—´æ ¼å¼: {time_str}, é”™è¯¯: {e}")
    
    def extract_segment_frames(self,
                              video_path: str,
                              start_time: str,
                              end_time: str,
                              output_dir: str) -> List[str]:
        """
        æå–æŒ‡å®šæ—¶é—´æ®µçš„è§†é¢‘å¸§å¹¶å»é‡

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            start_time: å¼€å§‹æ—¶é—´å­—ç¬¦ä¸²
            end_time: ç»“æŸæ—¶é—´å­—ç¬¦ä¸²
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            å»é‡åçš„å¸§å›¾ç‰‡è·¯å¾„åˆ—è¡¨
        """
        # è½¬æ¢æ—¶é—´æ ¼å¼
        start_seconds = self._parse_time_to_seconds(start_time)
        end_seconds = self._parse_time_to_seconds(end_time)

        # åˆ›å»ºè¯¥æ—¶é—´æ®µçš„è¾“å‡ºç›®å½•
        segment_dir = os.path.join(output_dir, f"segment_{start_time.replace(':', '-')}_to_{end_time.replace(':', '-')}")
        os.makedirs(segment_dir, exist_ok=True)

        # ä½¿ç”¨å®Œæ•´çš„å¤„ç†æµç¨‹ï¼ˆæŠ½å¸§ + å»é‡ï¼‰
        try:
            # ä¸åœ¨è¿™é‡ŒåŠ é”ï¼Œè®©æŠ½å¸§ç­‰æ­¥éª¤å¯ä»¥å¹¶å‘
            result = self.frame_deduplicator.process_video_frames(
                video_path=video_path,
                start_time=start_seconds,
                end_time=end_seconds,
                output_dir=segment_dir,
                fps=self.frame_fps,
                keep_temp_files=False,
                embedding_lock=self._embedding_lock  # ä¼ é€’é”ç»™å»é‡å™¨
            )

            # è·å–å®é™…çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            saved_paths = result.get("saved_paths", [])
            total_frames = result.get("total_frames", 0)
            unique_count = result.get("unique_frames", 0)

            self.logger.info(f"âœ… æ—¶é—´æ®µ {start_time}-{end_time}: {total_frames} å¸§ â†’ {unique_count} å¸§ï¼ˆå»é‡åï¼‰")
            return saved_paths

        except Exception as e:
            self.logger.error(f"âŒ æ—¶é—´æ®µ {start_time}-{end_time} å¸§å¤„ç†å¤±è´¥: {e}")
            return []

    def _process_single_segment(self, segment_data: tuple) -> dict:
        """
        å¤„ç†å•ä¸ªæ—¶é—´æ®µçš„å¸§æå–ï¼ˆç”¨äºå¹¶å‘è°ƒç”¨ï¼‰

        Args:
            segment_data: (segment_index, segment_dict, video_path, frames_dir, output_dir)

        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        i, segment, video_path, frames_dir, output_dir = segment_data

        start_time = segment.get("start_time", "")
        end_time = segment.get("end_time", "")
        summary = segment.get("summary", "")

        self.logger.info(f"ğŸ“ å¤„ç†æ—¶é—´æ®µ {i+1}: {start_time} - {end_time}")

        # æå–è¯¥æ—¶é—´æ®µçš„å…³é”®å¸§
        try:
            frame_paths = self.extract_segment_frames(
                video_path=video_path,
                start_time=start_time,
                end_time=end_time,
                output_dir=frames_dir
            )

            # è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„ï¼ˆä¾¿äºåç»­å¤„ç†ï¼‰
            relative_frame_paths = [
                os.path.relpath(path, output_dir) for path in frame_paths
            ]

        except Exception as e:
            self.logger.error(f"âŒ æ—¶é—´æ®µ {start_time}-{end_time} å¸§æå–å¤±è´¥: {e}")
            relative_frame_paths = []

        # æ„å»ºè¯¥æ—¶é—´æ®µçš„ç¬”è®°æ•°æ®
        note_segment = {
            "segment_id": i + 1,
            "start_time": start_time,
            "end_time": end_time,
            "duration_seconds": self._parse_time_to_seconds(end_time) - self._parse_time_to_seconds(start_time),
            "summary": summary,
            "key_frames": relative_frame_paths,
            "frame_count": len(relative_frame_paths)
        }

        return note_segment
    
    def generate_multimodal_notes(self,
                                 video_path: str,
                                 summary_json_path: str,
                                 output_dir: str) -> str:
        """
        ç”Ÿæˆå›¾æ–‡æ··æ’ç¬”è®°ï¼ˆæ”¯æŒæ—¶é—´æ®µçº§åˆ«å¹¶å‘å¤„ç†ï¼‰

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            summary_json_path: æ‘˜è¦JSONæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            ç”Ÿæˆçš„å›¾æ–‡ç¬”è®°JSONæ–‡ä»¶è·¯å¾„
        """
        # è¯»å–æ‘˜è¦æ•°æ®
        with open(summary_json_path, 'r', encoding='utf-8') as f:
            summary_data = json.load(f)

        summaries = summary_data.get("summaries", [])
        if not summaries:
            raise ValueError("æ‘˜è¦æ•°æ®ä¸ºç©º")

        self.logger.info(f"ğŸ¬ å¼€å§‹ç”Ÿæˆå›¾æ–‡ç¬”è®°ï¼Œå…± {len(summaries)} ä¸ªæ—¶é—´æ®µ")
        self.logger.info(f"ğŸ”„ å¹¶å‘å¤„ç†ï¼Œæœ€å¤§å¹¶å‘æ•°: {self.max_concurrent_segments}")

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        frames_dir = os.path.join(output_dir, "frames")
        os.makedirs(frames_dir, exist_ok=True)

        # å‡†å¤‡å¹¶å‘å¤„ç†çš„æ•°æ®
        segment_tasks = [
            (i, segment, video_path, frames_dir, output_dir)
            for i, segment in enumerate(summaries)
        ]

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†æ—¶é—´æ®µ
        multimodal_notes = []
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_concurrent_segments) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_index = {
                executor.submit(self._process_single_segment, task_data): task_data[0]
                for task_data in segment_tasks
            }

            # æ”¶é›†ç»“æœï¼ˆæŒ‰åŸå§‹é¡ºåºï¼‰
            results = {}
            for future in concurrent.futures.as_completed(future_to_index):
                index = future_to_index[future]
                try:
                    result = future.result()
                    results[index] = result
                    self.logger.info(f"âœ… æ—¶é—´æ®µ {index+1} å¤„ç†å®Œæˆ")
                except Exception as e:
                    self.logger.error(f"âŒ æ—¶é—´æ®µ {index+1} å¤„ç†å¤±è´¥: {e}")
                    # åˆ›å»ºä¸€ä¸ªç©ºçš„ç»“æœ
                    segment = summaries[index]
                    results[index] = {
                        "segment_id": index + 1,
                        "start_time": segment.get("start_time", ""),
                        "end_time": segment.get("end_time", ""),
                        "duration_seconds": 0,
                        "summary": segment.get("summary", ""),
                        "key_frames": [],
                        "frame_count": 0
                    }

            # æŒ‰é¡ºåºæ’åˆ—ç»“æœ
            for i in range(len(summaries)):
                if i in results:
                    multimodal_notes.append(results[i])

        # ç”Ÿæˆæœ€ç»ˆçš„å›¾æ–‡ç¬”è®°æ•°æ®
        final_notes = {
            "video_info": {
                "source_video": os.path.basename(video_path),
                "total_segments": len(multimodal_notes),
                "generated_at": datetime.now().isoformat(),
                "processing_mode": f"concurrent (max_workers={self.max_concurrent_segments})"
            },
            "segments": multimodal_notes,
            "statistics": {
                "total_frames": sum(note["frame_count"] for note in multimodal_notes),
                "segments_with_frames": len([note for note in multimodal_notes if note["frame_count"] > 0])
            }
        }

        # ä¿å­˜å›¾æ–‡ç¬”è®°
        output_file = os.path.join(output_dir, "multimodal_notes.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_notes, f, ensure_ascii=False, indent=4)

        self.logger.info("ğŸ‰ å›¾æ–‡ç¬”è®°ç”Ÿæˆå®Œæˆ!")
        self.logger.info(f"ğŸ“„ ç¬”è®°æ–‡ä»¶: {output_file}")
        self.logger.info("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        self.logger.info(f"   - æ€»æ—¶é—´æ®µ: {final_notes['statistics']['segments_with_frames']}/{len(multimodal_notes)}")
        self.logger.info(f"   - æ€»å…³é”®å¸§: {final_notes['statistics']['total_frames']}")
        self.logger.info(f"   - å¤„ç†æ¨¡å¼: å¹¶å‘å¤„ç† (æœ€å¤§{self.max_concurrent_segments}ä¸ªçº¿ç¨‹)")

        return output_file

    def export_to_markdown(self, notes_json_path: str, output_path: str = None,
                          image_base_path: str = None) -> str:
        """
        å°†å›¾æ–‡ç¬”è®°å¯¼å‡ºä¸º Markdown æ ¼å¼

        Args:
            notes_json_path: å›¾æ–‡ç¬”è®° JSON æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡º Markdown æ–‡ä»¶è·¯å¾„
            image_base_path: å›¾ç‰‡åŸºç¡€è·¯å¾„ï¼ˆç”¨äºè®¡ç®—ç›¸å¯¹è·¯å¾„ï¼‰

        Returns:
            ç”Ÿæˆçš„ Markdown æ–‡ä»¶è·¯å¾„
        """
        # è¯»å–ç¬”è®°æ•°æ®
        with open(notes_json_path, 'r', encoding='utf-8') as f:
            notes_data = json.load(f)

        if output_path is None:
            output_path = f"{Path(notes_json_path).stem}.md"

        # å¦‚æœæ²¡æœ‰æŒ‡å®šå›¾ç‰‡åŸºç¡€è·¯å¾„ï¼Œä½¿ç”¨ç¬”è®°æ–‡ä»¶çš„ç›®å½•
        if image_base_path is None:
            image_base_path = str(Path(notes_json_path).parent)

        # ç”Ÿæˆ Markdown å†…å®¹
        markdown_content = self._generate_markdown_content(notes_data, output_path, image_base_path)

        # ä¿å­˜æ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)

        self.logger.info(f"ğŸ“ Markdown ç¬”è®°å·²å¯¼å‡º: {output_path}")
        return output_path


    def _generate_markdown_content(self, notes_data: Dict[str, Any],
                                  output_path: str = None,
                                  image_base_path: str = None) -> str:
        """ç”Ÿæˆ Markdown å†…å®¹"""
        video_info = notes_data.get("video_info", {})
        segments = notes_data.get("segments", [])
        statistics = notes_data.get("statistics", {})

        # æ„å»º Markdown
        lines = []

        # æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
        lines.append(f"# ğŸ“¹ è§†é¢‘ç¬”è®°ï¼š{video_info.get('source_video', 'æœªçŸ¥è§†é¢‘')}")
        lines.append("")
        lines.append("## ğŸ“Š åŸºæœ¬ä¿¡æ¯")
        lines.append("")
        lines.append(f"- **è§†é¢‘æ–‡ä»¶**: {video_info.get('source_video', 'æœªçŸ¥')}")
        lines.append(f"- **ç”Ÿæˆæ—¶é—´**: {video_info.get('generated_at', 'æœªçŸ¥')}")
        lines.append(f"- **æ€»æ—¶é—´æ®µ**: {video_info.get('total_segments', 0)}")
        lines.append(f"- **æ€»å…³é”®å¸§**: {statistics.get('total_frames', 0)}")
        lines.append(f"- **æœ‰æ•ˆæ—¶é—´æ®µ**: {statistics.get('segments_with_frames', 0)}")
        lines.append("")

        # ç›®å½•
        lines.append("## ğŸ“‘ ç›®å½•")
        lines.append("")
        for i, segment in enumerate(segments, 1):
            start_time = segment.get("start_time", "")
            end_time = segment.get("end_time", "")
            lines.append(f"{i}. [{start_time} - {end_time}](#æ—¶é—´æ®µ-{i})")
        lines.append("")

        # è¯¦ç»†å†…å®¹
        lines.append("## ğŸ“ è¯¦ç»†å†…å®¹")
        lines.append("")

        for i, segment in enumerate(segments, 1):
            start_time = segment.get("start_time", "")
            end_time = segment.get("end_time", "")
            duration = segment.get("duration_seconds", 0)
            summary = segment.get("summary", "")
            key_frames = segment.get("key_frames", [])

            # æ—¶é—´æ®µæ ‡é¢˜
            lines.append(f"### æ—¶é—´æ®µ {i}")
            lines.append("")
            lines.append(f"**â° æ—¶é—´**: {start_time} - {end_time} ({duration:.1f}ç§’)")
            lines.append("")

            # æ‘˜è¦å†…å®¹
            lines.append("**ğŸ“‹ æ‘˜è¦**:")
            lines.append("")
            lines.append(summary)
            lines.append("")

            # å…³é”®å¸§
            if key_frames:
                lines.append(f"**ğŸ–¼ï¸ å…³é”®å¸§** ({len(key_frames)}å¼ ):")
                lines.append("")
                for frame_path in key_frames:
                    frame_name = Path(frame_path).name

                    # ç›´æ¥æ‹¼æ¥æ­£ç¡®çš„è·¯å¾„ï¼š/storage/tasks/{task_id}/multimodal_notes/frames/segment_xxx/unique_frame_xxx.jpg
                    if image_base_path:
                        # image_base_path æ˜¯ task_dirï¼Œå³ /storage/tasks/{task_id}
                        image_path = f"/{image_base_path}/multimodal_notes/{frame_path}"
                    else:
                        # å¤‡ç”¨æ–¹æ¡ˆ
                        image_path = f"multimodal_notes/{frame_path}"

                    lines.append(f"![{frame_name}]({image_path})")
                lines.append("")
            else:
                lines.append("*è¯¥æ—¶é—´æ®µæ— å…³é”®å¸§*")
                lines.append("")

            lines.append("---")
            lines.append("")

        # é¡µè„š
        lines.append("## ğŸ”§ ç”Ÿæˆä¿¡æ¯")
        lines.append("")
        lines.append("æœ¬ç¬”è®°ç”±è§†é¢‘å¤„ç† API è‡ªåŠ¨ç”Ÿæˆ")
        lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        if output_path:
            lines.append(f"è¾“å‡ºæ–‡ä»¶: {output_path}")

        return "\n".join(lines)



# ä¾¿æ·å‡½æ•°
def generate_video_notes(video_path: str,
                        summary_json_path: str,
                        output_dir: str,
                        cohere_api_key: str,
                        frame_fps: float = 0.5,
                        max_concurrent_segments: int = 3,
                        logger: Optional[logging.Logger] = None) -> str:
    """
    ä¾¿æ·å‡½æ•°ï¼šç”Ÿæˆè§†é¢‘çš„å›¾æ–‡æ··æ’ç¬”è®°ï¼ˆæ”¯æŒå¹¶å‘å¤„ç†ï¼‰

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        summary_json_path: æ‘˜è¦JSONæ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        cohere_api_key: COHERE_API_KEYå¯†é’¥
        frame_fps: æŠ½å¸§é¢‘ç‡
        max_concurrent_segments: æœ€å¤§å¹¶å‘å¤„ç†çš„æ—¶é—´æ®µæ•°é‡
        logger: æ—¥å¿—è®°å½•å™¨

    Returns:
        ç”Ÿæˆçš„å›¾æ–‡ç¬”è®°JSONæ–‡ä»¶è·¯å¾„
    """
    generator = MultimodalNoteGenerator(
        cohere_api_key=cohere_api_key,
        frame_fps=frame_fps,
        max_concurrent_segments=max_concurrent_segments,
        logger=logger
    )
    
    return generator.generate_multimodal_notes(
        video_path=video_path,
        summary_json_path=summary_json_path,
        output_dir=output_dir
    )


