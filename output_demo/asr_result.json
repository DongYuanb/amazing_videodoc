[
    {
        "text": "All right thank you thank you everyone for joining us ah so we're picking up with prompting for agents um hopefully you were here for prompting one and one or maybe you're just joining us but I'LL give a little introro my name's hanah I'm part of the applied to I team and I'mthrop hi I'm Jeremy I'm on our applied the I as well and I'm a product engineer so we're gonna to talk about prompting for agents so we're going tos Switch gears a little bit move on for the basics of prompting and talk about how we do this for agents like playing pokemon so hopefully you'were here uh for prompting when I wonder maybe you have some familiarity with basic prompting so we're not going to go over um the really kind of basic console prompting or interacting with claw in the deskstop today but just a refreshher we think about prompt engineering is kind of programming and natural language you're thinking about what your agent or your model is going to be doing what kind of tasks it's accomplishing you're trying to clearly communicate to the agent give examples we're necessary um and give guidelines em we do you know if all kind of a very specific.",
        "start_time": 5380,
        "end_time": 65860
    },
    {
        "text": "Structure for console prompting I want you to remove this from your minds because it could look very different for an agent so for an agent you may not be laying out this type of very structured prompt it's actually going to look a lot different we're going to allow a lot of different things to come in so I'm going to turn it over I'm going to talk about what agentians are and then I'LL turn it over to Jeremy to talk about how we do this for agents so hopefully you have a sense in your mind of what an agent is and out topic we like to say that agents aren't models using tools in a loop so we give the agent a task and we allow it to work continuously and use tools as it thinks fit um updateds decisions based on the information that is'getting back from its tool calls and continue working independently until it completes the task so that's we kind of keep it as simple as that the environment which is where the is working the tools that the agent has and the system prompt is just where we tell the agent what it should be doing or what it should be accomplishing and we typically find the simpler you can keep this the better allow the agent.",
        "start_time": 65860,
        "end_time": 125900
    },
    {
        "text": "To do its work allow the model to be the model and kind of work through this task.",
        "start_time": 125900,
        "end_time": 131060
    },
    {
        "text": "So when do you use agents you do not always need to use an agent in fact there's many scenarios in which you won't actually want to use an agent there are other approaches that would be more appropriate um agents are really best for complex and valuable tasks it's not something you should deploy in every possible scenario you will not get the results that you want um and you'LL spend a lot more resources than you maybe need to so we'talk a little bit about checklist or or kind of ways of thinking about when you should be using an agent maybe you don't want to be using an agent so is a task complex is this a task that you a human can think through a step by step process to complete if so you probably don't need an agent you want to use an agent where it's not clear to you how you'LL go about accomplishing the task you might know where you want to go but you don't know exactly how you're going to get there what tools and what information you might need to arrive at the end state is a task valuable are you going to get a lot of value out of the agent accomplishing this task or is this a kind of a low value.",
        "start_time": 131060,
        "end_time": 191420
    },
    {
        "text": "ER workloop in that case of work flow might also be better you don't really want to be using the resources of an agent unless this is something you get the highly leverage it's maybe revenue generating it's something that's really valuable to your user again it's something that's complex uh the last next pieces are the parts of the task doable so when you think about the task that has to occur would you be able to give the Asians the tools that it needs in order to accomplish this task if you can't define the tools if you can't give the Asian access to the information or the tool that it would need you may want to scope the task down um if you can define and give to the Asian the tools that it would want that's a better use case for an Asian.",
        "start_time": 191420,
        "end_time": 231080
    },
    {
        "text": "The last thing you might want to think about is the cost of errors or how easy it is to discover errors so if it's really difficult to correct an error detect an error that is maybe not a place where you want the agent to be working independently you might want to have a human in the loop in that case if the error is something that you can recover from or if it's not too costly to have an error occurring then you might continue to allow the agent to work independently.",
        "start_time": 231180,
        "end_time": 256720
    },
    {
        "text": "So to make this a little bit more real we'LL talk about a few examples I'm not going to go through each single one of these but let's pick out a few that will'be pretty clear intuitive for most of us so coding obviously em all of you are very familiar with using agents and coding coding is a great use case we can think about something like a design document and although you know where you want to get to which is raising a PR you don't know exactly how you're going to get there it's not clear to you what you're a build first how you'lliterate on that what changes you might make along the way depending on what you find em this is high value you're all very skilled if an agent BOO OK if an agent is able.",
        "start_time": 257160,
        "end_time": 296660
    },
    {
        "text": "This is like more like what the midway is like at night I feel I feel more at home now clat is clat is greater coding and this is a high value use case right if your agent is actually able to go from a design document to a PR that's a lot of time that you a highly skills engineer are saved and you're able to spend spend your time on something else it's higheri leverage so great use case for agents couple other examples I'LL mentioned here um neighbor will'talk about the the cost of error so search if we make an error in the search there's ways that we can correct that right so we can use citations we can use other methods of double checking the results so if the agent makes a mistake in the search process this is something we can recover from and it's probably not too costly.",
        "start_time": 296660,
        "end_time": 342740
    },
    {
        "text": "Computer use em this is also a place where we can recover from errors we might just go back we might try clicking again it's not too difficult to allow claud just to click a few times until it's able to use the tool properly um data analysis I think is another interesting example kind of analog to coding we might know the end result that we want to get to we know a set of insights that we want to gather out of data or a visualization that we want to produce from data we don't know exactly what the data might look like so the data could have different formats it could have errors in it it could have other it could have granularity issues that we're not sure how to disagegggregate we don't know the exact process that we're going to take and analyzing that data but we know where we want to get in the end so this is another example of a great use case for agents.",
        "start_time": 342880,
        "end_time": 389480
    },
    {
        "text": "So hopefully these make sense to you and I'm going to turn it over to jerremy now he has some really rich experience building agents set ofthropic and he's going to share some best practices for actually prompting them well and how to structure a great prompt for an agent thanks Anna I all yeah so prompting for agents I think some things that we think about here I'LLI'LL go over a few of them we'VE learned these experiences mostly from building agents ourselves so some agents that you can try from anthropic are cloud code which works in your terminal and sort of aentticly browseuses your files and use the Bach tool to really accomplish tasks em encoding similarly we have our new a advanced research feature in cloud do AI and this allows you to do hours of research for example you can find hundreds of start startups building agents or you can find hundreds of potential prospects for your company.",
        "start_time": 389580,
        "end_time": 439040
    },
    {
        "text": "And this allows the model to do research across your tools your Google drive web search and stuff like that.",
        "start_time": 439040,
        "end_time": 445940
    },
    {
        "text": "And so in the process of building these products one things that we learned is that you need to think like your agents this is maybe the most important principle em the idea is that essentially you need to understand and develop a mental model of what your agent is doing and what it's like to be in that environment so the environment for the agent is a set of tools and the responses that gets back from those tools and the context of cloud code the way you might do this is by actually simulating the process and just imagining if you were in cloud codes choose given the exact tool descriptions it has and the tool scheme as it has would you be confused or would you be able to do do the task that it's doing.",
        "start_time": 445940,
        "end_time": 481680
    },
    {
        "text": "If a human can't understand what your agent should be doing then an AI will not be able to either and so this is really important for thinking about tool design thinking about prompting is to simulate it and go through their environment.",
        "start_time": 481680,
        "end_time": 493280
    },
    {
        "text": "Another is that you need to give your agents reasonable heuristics and so you know Hanna mentioned that prompt engineering is conceptual engineering what does that really mean it's one of the reasons why prompt engineering is not going away and why I personally expect prompting to get more important not less important as models get smarter this is because prompting is not just about text it's not just about the words that you give the model it's about deciding what concepts the model should have and what behavior is it should follow to perform well in a specific environment.",
        "start_time": 493540,
        "end_time": 522020
    },
    {
        "text": "So for example cloudud code has the concept of irreversibility it should not take irreversible actions that might harm the user or harm their environment so it will avoid these kinds of harmful actions or anything that might cause irreversible damage to your environment or to your code or anything like that so that concept of irreversibility is something that you need to instill in the model and be very clear about and think about the edge cases how might the model in misinterpret this concept how might it not know what it means for example if you want the model to be very eager and you want it to be very agenntic well it might go over the top a little bit it might misinterpent what you're saying and do more than what youre expect and so you have to be very crisp and clear about the concepts are giving the models em some examples of these reasonable heuristics that we'VE learned one is that while we were building research we noticed that the model would often do a ton of web searches when it was unnece for example it would find the actual answer it needed like maybe find a list of scale UPS in the United States and then it would keep going even though it already had the answer.",
        "start_time": 522020,
        "end_time": 582380
    },
    {
        "text": "And that's because we hadn't told the explicitly when you find the answer you can stop you no longer need to keep searching uh similarly we hadn to give the model sort of budgets to think about for example we told that that for simple querries it should use under five tool calls but for more complex querries and might use up to ten or fifteen so these kinds of heuristics that you might assume the model already understands you really have to articulate clearly a good way to think about this is that if you're managing maybe a new intern whose'spread out of college and is not had a job before.",
        "start_time": 582380,
        "end_time": 613300
    },
    {
        "text": "How would you articulate to them how to get around all the problems they might get run into and their first job and how would you be very crisp and clear with them about how to accomplish that that's often how you should think about giving youristics your agents which are just general principles that it should follow they may not be strict rules but they're you know sort of practices another point is that tool selection is key so as models get more powerful able to handle more and more tools sign it and opus for I can handle you know up to a hundred tools even more than that if you have great prompting but in order to use these tools you have to be clear about which tools that you use for different tasks so for example for research we can give the model access to Google drive we can give it access to m cp tools like century or data do or github it can search across all these tools but the model doesn't know already which tools are important for wish tasks especially in your specific company context for example if your company use a slack a lot maybe it should default to searching slack for company related information.",
        "start_time": 613300,
        "end_time": 671760
    },
    {
        "text": "All these questions about how the model should use tools you have to give it explicit principles about when to use which tools and in which context em and this is really important and it's often something I see where people don't prompt the agent at all about which tools to use and they just give the models some tools with some very short descriptions and then they wonder like why is in the model using the right tool well it's likely because the model doesn't know what it should be doing in that context.",
        "start_time": 671760,
        "end_time": 698060
    },
    {
        "text": "Another point here is that you can guide the thinking process so people often sort of turn extend to thinking on and then let their agents run and assume it will get out of the box better performance actually that assumption is true most of the time you will get out of the box better performance but you can squeeze even more performance out of it if you just prompt the agent to use its thinking well so for example for search what we do is tell the model to plan out its search process so in advance it'should decide how complicated as this query how many tool calls should to use here what sources should I look for how will I know what I'm successful we tell it to plan out all these exact things in its first thinking block and then a new capability about the cloud four models have is the ability to use inner leave thinking between tool calls so after getting results from the web we often find that models assumed that all web search results are true right they don't have any you know we we haven't told them explicitly that this isn't the case and so they might take these web results and run with them immediately so one thing we prompt that our models to do is to use this inner leaf thinking.",
        "start_time": 698060,
        "end_time": 758320
    },
    {
        "text": "'really reflect on the quality of the search resultts and decide if they need to verify them if they need to get more information or if they should add a disclaimer about how the results might not be accurate.",
        "start_time": 758320,
        "end_time": 767880
    },
    {
        "text": "Em another point with when prompting agents is that agents are more unpredictable then work flowws or just you know classification type prompts most changes will have unintended side effects this is because agents will operate an a loop autonomously and so for example if you tell the agent you know keep searching until you find the correct answer you know find the highest quality possible source and always keep searching until you find that source what you might run into is the unintended side effect of the agent just not finding any sources maybe this perfect source doesn't exist for the for the query and so it will just keep searching until it hits its context window and that's actually what we ran into as well and so you have to tell the agent if you don't find the perfect source that's okay you can stop after a few tool calls em so just be aware that your prompt may have unintended side effects and you may have to roll those back.",
        "start_time": 767880,
        "end_time": 818700
    },
    {
        "text": "Another point is to help the agent manage its context window the cloud for models have a two hundred k token context window em this is long enough for a lot of long running tasks but when you're using an agent to do work autonomously you may hit this context window and there are several strategies you can use to sort of extend the effective context window.",
        "start_time": 818700,
        "end_time": 837220
    },
    {
        "text": "One of them that we use for a cloudud code is called compassion and this is just a tool that the model has em that will automatically be called once it hits around a hundred and ninety thousand tokens so near the context window and this will summarize or compress everything in the context window to a really dense but accurate summary that is then pass to a new instance of clad with the summary and it continues the process and we find that this essentially allows you to run infinitely with cloud code you almost never run out of context um occasionally it will Miss details from the previous session but the vast majority of the time this will keep all the important details and the model will sort of remember what happened in the last session.",
        "start_time": 837220,
        "end_time": 874500
    },
    {
        "text": "Similarly you can sort of write to an external file so the model can have access to an extra file and these cloud models are especially good at writing memory to a file and they can use this file to essentially extend their context window.",
        "start_time": 874600,
        "end_time": 888500
    },
    {
        "text": "Another point is that you can use sub agents em we won't talk about this a lot here but essentially if you have agents that are always hit their context Windows you may delegate some of what the agent is doing to another agent em which can sort of for example you can have one agent be the lead agent and then sub agents do the actual searching process then the sub agents can compress the results to the lead agent in a really dense form that doesn't use as many tokens and the lead agent can give the final report to the user.",
        "start_time": 888680,
        "end_time": 917260
    },
    {
        "text": "So we actually use this process in our research system and this allows you to sort of compress what's going on in the search and then only use the context window for the lead agent for actually writinging the report so this kind of multigen system can be effective for limiting the context window.",
        "start_time": 917260,
        "end_time": 932680
    },
    {
        "text": "Finally you can let claud be claud and essentially what this means is that claud is great at being an agent already you don't have to do a ton of work at the very beginning so I would recommend just trying out your system with sort of a bare bones prompt and bare bones tools and seeing where it goes wrong and then working from there don't sort of assume thatlod can't do it ahead of time becauselot often will'surprise you with how good it is.",
        "start_time": 932820,
        "end_time": 955000
    },
    {
        "text": "Em I talked to already about tool design but essentially to key point here is you want to make sure that your tools are good em what is a good tool it will have a simple accurate tool name that reflects what it does you'LL have tested it and make sure that it works well em it'LL have a well form description so that a human reading this tool like imagine you give a function to another engineer on your team would they understand this function and be able to use it you should ask the same question about the agent computer interfaces or the tools that you are giving your agent make sure that they're usable and clear em we also often find that people will give an agent a bunch of tools that have very similar names or descriptions so for example you give it six search tools and each of the search tools searches a slightly different database this will confuse the model so try to keep your tools fairly distinct and combine similar tools into just one.",
        "start_time": 956160,
        "end_time": 1008420
    },
    {
        "text": "So one e quick example here is just that you can have an agent for example use these different tools to first look search the inventory in a database run a query based on the information it finds it can reflect on the inventory think about it for a little bit then decide to generate anvoice generate this invoice think about what it should do next and then decide to send an email and so this loop involves the agent getting information from the database which is its external environment using its tools and then updating based on that information and tell it accomplishes the task and that'sort of how agents work in general.",
        "start_time": 1009620,
        "end_time": 1042200
    },
    {
        "text": "So let's walk through a DEMO real quick I'LL Switch to my computer em so you can see here that this is our console the console is a great tool for sort of simulating your prompts and seeing what they would look like in a UI em and I use this while we were editerating on research to sort of understand what's really going on and what the agents doing this is a great way to think like your agents and sort of put yourself in their shoes so you can see we have a big prompt here em it's not sort of super long it's around a thousand tokens it involves the researcher going through a research process we tell it exactly what should what it what it should plan ahead of time we tell it how many tool calls it should typically use we give us some guidelines about what facts it should think about what makes the high quality source stuff like that and then we tell it to use parallel calls so you know run multiple web searches in parallel at the same time rather than running them all sequentially.",
        "start_time": 1042740,
        "end_time": 1093320
    },
    {
        "text": "Then we give it this question how many bananas can fit in iivian r one s this is not a question that the model will be able to answer because theivian r one s came out very recently zcar it doesn't know in advance all this specifications and everything so it'will have to search the web let's run it and see what happens you'LL see that at the very beginning it will think and break down this request and so it realizes okay web searches going to be helpful here I should get cargo capacity I should search em wooh em and you see here it ran two web searchs in parallel at the same time not allowed it to get these results back very quickly and then it's reflecting on the results so it's realizing okay I found the banana dimensions I know that the us s d identifies banana as as seventy eight inches long.",
        "start_time": 1093320,
        "end_time": 1137660
    },
    {
        "text": "I need to run another web search let me convert these DEMO more standard measurements you can see it's using tool calls innerlied with thinking which is something new that the quad for models can do finally it's running some calculations it's thinking about how many bananas could be packed into the cargo space of the truck.",
        "start_time": 1137660,
        "end_time": 1153040
    },
    {
        "text": "And it's running a few more web searches you can see here that this is a fairly complex task but it can now provide an answer it's done a bunch of webes and it will tell you how many bananas can fit.",
        "start_time": 1154040,
        "end_time": 1166060
    },
    {
        "text": "Pending.",
        "start_time": 1168260,
        "end_time": 1169640
    },
    {
        "text": "Approximately forty eight thousand bananas I'VE seen the model estimate any between thirty thousand fifty thousand I think the right answer is around thirty thousand so this is this is roughly correct going back to the slides.",
        "start_time": 1171300,
        "end_time": 1184520
    },
    {
        "text": "I think that you know this this sort of approach of testing out your prompt seeing what tools the model calls reading it's thinking blocks and actually seeing how the model is thinking well'LL often make it really obvious what the issues are and what's going wrong so you'LL test it out and you'LL just see like okay maybe the models using two me tools here maybe it's using the wrong sources or maybe it's just following the wrong guidelines em so this is a really helpful way to sort of think like your agents and make them more concrete.",
        "start_time": 1185700,
        "end_time": 1214280
    },
    {
        "text": "Searching back to the slides.",
        "start_time": 1217100,
        "end_time": 1220000
    },
    {
        "text": "Okay so evas evaluations are really important for any system em they'are really important for systematically measuring whether you're making progress in your prompt very quickly you'LL notice that it's difficult to really make progress on a prompt if you don't have an e VO that tells you meaningfully whether your prompt is getting better and whether your system is getting better.",
        "start_time": 1223540,
        "end_time": 1242980
    },
    {
        "text": "But evas are much more difficult for agents em agents are long running they do a bunch of things they may not they may not always have a predictable process classification is easier to e email because you can just check did it class of high this output correctly but agents are harder so a few tips to make this a bit easier one is that the larger the effect size the smaller the sample size you mean you need em and so this is sort of just a principle from science in general where if an effect size is very large for example if a medication will cure people immediately you don't really need a large example size of a ton of people to know that that model is that that this treatment is having an effect similarly when you change a prompt if it's really obvious that the system is getting better you don't need a large EVA I often see teams think that they need to set up a huge EVA of like hundreds of test cases and make it completely automated when they're just starting out building an agent.",
        "start_time": 1242980,
        "end_time": 1295180
    },
    {
        "text": "This is a failure mode and it's an anti pattern you should start out with a very small EVA and just run it and see what happens you can even start out manually em but the important thing is to just get started ice oftenan see teams delaying evos because they think that they're so intimidating or that they need such a sort of intense EVA to really get some signal but you can get great signal from a small number of test cases you just want to keep those test cases consistent and then keep testing them so you know whether the model and the prompt is getting better.",
        "start_time": 1295180,
        "end_time": 1324120
    },
    {
        "text": "You also want to use realistic tasks so I don't just sort of come up with arbitrary prompt or descriptions or tasks that don't really have any real correlation to what your system will be doing for example if you're working on coding tasks you don't want'don't won't want to give the model just competitive programming problems because this is not what real world coding is like you'LL want to give it realistic tasks that really reflect what your agent will be doing similarlyly in finance you'LL want to sort of take tasks that real people are trying to solve.",
        "start_time": 1324380,
        "end_time": 1351940
    },
    {
        "text": "And just use them to evaluate whether the model can do those this allows you to really measure whether the model is getting better at the task that you care about another point is that element is judge is really powerful especially when you give it a rubricick so agents will have lots of different kinds of outputs for example if you're using them for search they might have tons of different kinds of search reports with different kinds of structure but els are great at handling lots of different kinds of structure and tas with different characteristics and so one thing that we'VE done for example is given the model just to clear rubric.",
        "start_time": 1351940,
        "end_time": 1382520
    },
    {
        "text": "And then ask it to evaluate the output of the agent for example for search tasks we might give it a rubricck that says check that the model you know em looked at the right sources check that it got the correct answer in this case we might say em check with the model gas that the amount of bananas that can fit in riving our r when us is between like ten thousand and fifty thousand anything outside that range is not realistic so you know we you can use things like that to'sort of benchmark whether the model is getting the right answer is whether it's following the right process.",
        "start_time": 1382520,
        "end_time": 1412820
    },
    {
        "text": "At the end of the day though nothing is a perfect replacement for human evas you need to test the system manually you need to see what it's doing you need to sort of look at the transcripts look at what the model is doing and sort of understand your system if you want to make progress on it.",
        "start_time": 1413180,
        "end_time": 1427140
    },
    {
        "text": "Here's some examples of emails for agents so one example that I sort of showed talked about is answer accuracy and this is where you just use an l m is judge to judge whether the answer is a so for example in this case you might say the agent needs to user a tool to query the number of employees and number of report the answer and then you know the number of employees that your company so you can just check that with an elementla is's judge the reason you use an elementla is's judge here is because it's more robust to variations for example if you're just checking for the integer forty seven in this case in the output that is not very robust and if the model says forty seven is text you'LL greater incorrectly so you want to use an album is judge there to be robust to those minor variations.",
        "start_time": 1427680,
        "end_time": 1467000
    },
    {
        "text": "Another way you can EVO agents its tool use accuracy agents involve using tools in a loop and so if you know in advance what tools the model should use or how it should use them you can just evaluate if it use the correct tools in the process for example in this case I might evaluate the agent should use web search at least five times to answer this question and so I could just check in the transcript programmatically did the tool call for web search appear five times or not similarly you might check in this case in response to the question book a flight the agent should use the search flights tool and you can just check that programmatically and this allows you to make sure that the right tools are being used at the right times.",
        "start_time": 1467000,
        "end_time": 1505980
    },
    {
        "text": "Finally a really good EVO for agents is tow bench you can sort of look this up tow bench is a sort of open source benchmark that shows that you can evaluate whether agents reach the correct final state so a lot of agents are sort of modifying a database or interacting with a user in a way where you can say the models should always get to this state at the end of the process for example if your agent is a customer service agent for airlines and the user asks to change their flight.",
        "start_time": 1506020,
        "end_time": 1535260
    },
    {
        "text": "At the end of the agentic process in response to that prompt it should have changed the flight in the database and so you can just check at the end of the agentic process was the flight changed was this row in the database change to a different date and that can verify that the agents working correctly this is really robust and you can use it a lot in a lot of different use cases for example you can check that your database is updated correctly you can check that certain files were modified things like that as a way to evaluate the final state that the agent reaches and that's it from us we're happy to take your questions.",
        "start_time": 1535260,
        "end_time": 1575340
    },
    {
        "text": "Can you talk about building prompt for agentgings are you giving it kind of longer prompts first and then editerating or you starting kind of chunk by chunkk what's that look like in key shows sort of a little bit more on that dot process.",
        "start_time": 1577280,
        "end_time": 1589620
    },
    {
        "text": "That's a great question em can I Switch back to my screen actually I just want to sort of show the DEMO thank you em yeah so you can see this is sort of a final prompt that we'VE arrived at but this is now where we started I think the answer to your question is that you start with a short simple prompt so in this case I might start with something very short you know I'LL just delete this for now and I'LL say like search the web.",
        "start_time": 1589680,
        "end_time": 1611440
    },
    {
        "text": "To answer the question.",
        "start_time": 1611440,
        "end_time": 1613460
    },
    {
        "text": "Um.",
        "start_time": 1614260,
        "end_time": 1616000
    },
    {
        "text": "And I might just say search the web aenttically I'LL change this to a different question em how good are the cloudud four models and then we'LL just run that and so you'LL want to start with something very simple and just see how it works you'LL often find the cloud can do the task well out of the box but if you have more needs and you needed to operate really consistently in production you'LL notice edge cases or small flaws as you test with more use cases and so you'LL sort of add those into the prompt so I would say building an agent prompt what it looks like concretely is start simple test it out see what happens inrate from there start collecting test cases where the model fails or succeeds and then over time try to increase the number of task cases that pass and the way to do this is by sort of adding instructions adding examples to the prompt.",
        "start_time": 1616700,
        "end_time": 1663900
    },
    {
        "text": "But you really only do that when you find out what the edge cases are and you can see that it thinks that the models are indeed good so that's great.",
        "start_time": 1663900,
        "end_time": 1673640
    },
    {
        "text": "When I do like normal prompting and it's not agetic I'LL often give like a few shot example of like hey here's like input here's output this works really well for like classification tasks that right is there a parallel here in this like a genetic world are you finding that that's ever helpful or should I not think about it that way that is a great question yeah so should you include few shot examples in your prompt and sort of.",
        "start_time": 1673640,
        "end_time": 1696160
    },
    {
        "text": "A traditional prompting techniques involved like giving the saying the model should use a chain of thought and then giving a few shot examples like a bunch of examples to imitate we find that these techniques are not as effective for state of the art frontier models and for agents um the main reason for this is that if you give the model a bunch of examples of exactly what process should follow that just limits the model too much these models are smarter than you can predict and so you don't want to tell them exactly what they need to do similarly chain of thought has just been trained into the models at this point the models know to think in advance they don't need to be told like ch use chain of thought but what we can do here is one you can tell the model how to use it's thinking so you know I talked about earlier rather than telling the model you need to use a chain of thought it already knows that you can just say use your thinking process to plan out your search or to plan out what you're going to do in terms of coding remember or you can tell it to remember specific things and its thinking process and that sort of helps the agents stay on track.",
        "start_time": 1696160,
        "end_time": 1752520
    },
    {
        "text": "As far as examples go em you'LL want to give the model examples but not too pre scriptive I think we are out of time but you can come up to me partly and I'LL talk to you all after.",
        "start_time": 1752520,
        "end_time": 1761720
    },
    {
        "text": "Thank you.",
        "start_time": 1762180,
        "end_time": 1764646
    }
]