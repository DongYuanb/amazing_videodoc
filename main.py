#!/usr/bin/env python3
"""
è§†é¢‘å¤„ç†å·¥ä½œæµç¨‹ç¼–æ’å™¨ - FastAPI æœåŠ¡
"""
import os
import json
import uuid
import shutil
import logging
from pathlib import Path
from typing import Optional, Dict, List
from datetime import datetime

from fastapi import FastAPI, UploadFile, File, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from dotenv import load_dotenv

from asr_tencent.text_merge import TextMerger
from asr_tencent.summary_generator import Summarizer
from asr_tencent.asr_service import ASRService
from ffmpeg_process import extract_audio_for_asr
from multimodal_note_generator import MultimodalNoteGenerator

load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('video_processing.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# API æ•°æ®æ¨¡å‹
class TaskStatus(BaseModel):
    task_id: str
    status: str  # pending, processing, completed, failed
    current_step: Optional[str] = None
    progress: float = 0.0
    created_at: str
    updated_at: str
    error_message: Optional[str] = None

class ProcessRequest(BaseModel):
    start_from: str = "audio_extract"
    enable_multimodal: bool = True
    keep_temp: bool = False

# ç®€å•çš„ä»»åŠ¡ç®¡ç†å™¨
class TaskManager:
    """åŸºäºæ–‡ä»¶ç³»ç»Ÿçš„ç®€å•ä»»åŠ¡ç®¡ç†"""

    def __init__(self, storage_dir: str = "storage"):
        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(exist_ok=True)
        self.tasks_dir = self.storage_dir / "tasks"
        self.tasks_dir.mkdir(exist_ok=True)

    def create_task(self, original_filename: str) -> str:
        """åˆ›å»ºæ–°ä»»åŠ¡"""
        task_id = str(uuid.uuid4())
        task_dir = self.tasks_dir / task_id
        task_dir.mkdir(exist_ok=True)

        # åˆ›å»ºä»»åŠ¡å…ƒæ•°æ®
        metadata = {
            "task_id": task_id,
            "original_filename": original_filename,
            "status": "pending",
            "current_step": None,
            "progress": 0.0,
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat(),
            "error_message": None
        }

        self.save_metadata(task_id, metadata)
        return task_id

    def get_task_dir(self, task_id: str) -> Path:
        """è·å–ä»»åŠ¡ç›®å½•"""
        return self.tasks_dir / task_id

    def save_metadata(self, task_id: str, metadata: dict):
        """ä¿å­˜ä»»åŠ¡å…ƒæ•°æ®"""
        task_dir = self.get_task_dir(task_id)
        with open(task_dir / "metadata.json", "w", encoding="utf-8") as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)

    def load_metadata(self, task_id: str) -> dict:
        """åŠ è½½ä»»åŠ¡å…ƒæ•°æ®"""
        task_dir = self.get_task_dir(task_id)
        metadata_file = task_dir / "metadata.json"
        if not metadata_file.exists():
            raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

        with open(metadata_file, "r", encoding="utf-8") as f:
            return json.load(f)

    def update_status(self, task_id: str, status: str, current_step: str = None,
                     progress: float = None, error_message: str = None):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        metadata = self.load_metadata(task_id)
        metadata["status"] = status
        metadata["updated_at"] = datetime.now().isoformat()

        if current_step is not None:
            metadata["current_step"] = current_step
        if progress is not None:
            metadata["progress"] = progress
        if error_message is not None:
            metadata["error_message"] = error_message

        self.save_metadata(task_id, metadata)

class VideoProcessingWorkflow:
    """è§†é¢‘å¤„ç†å·¥ä½œæµç¨‹ç¼–æ’å™¨ï¼šä¸“æ³¨äºæµç¨‹ç¼–æ’ï¼ŒåŠŸèƒ½æ¨¡å—è§£è€¦"""

    def __init__(self,
                 model_id:str="openrouter/horizon-beta",
                 ffmpeg_path:str="ffmpeg",
                 asr_appid:str=None,
                 asr_secret_id:str=None,
                 asr_secret_key:str=None,
                 jina_api_key:str=None,
                 enable_multimodal:bool=True):
        self.model_id=model_id
        self.enable_multimodal = enable_multimodal

        # åˆå§‹åŒ–å„ä¸ªåŠŸèƒ½æ¨¡å—
        self.ffmpeg_path = ffmpeg_path
        self.text_merger = TextMerger(model_id)
        self.summary_generator = Summarizer(model_id)
        self.asr_service = self._init_asr_service(asr_appid, asr_secret_id, asr_secret_key)

        # åˆå§‹åŒ–å›¾æ–‡ç¬”è®°ç”Ÿæˆå™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.enable_multimodal:
            self.multimodal_generator = self._init_multimodal_generator(jina_api_key, ffmpeg_path)

    def _init_asr_service(self, appid, secret_id, secret_key):
        """åˆå§‹åŒ– ASR æœåŠ¡"""
        # å¦‚æœæ²¡æœ‰æä¾›å‚æ•°ï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼è·å–
        if not appid:
            appid = os.getenv("TENCENT_APPID")
        if not secret_id:
            secret_id = os.getenv("TENCENT_SECRET_ID")
        if not secret_key:
            secret_key = os.getenv("TENCENT_SECRET_KEY")

        try:
            return ASRService(appid, secret_id, secret_key)
        except ValueError as e:
            raise RuntimeError(f"ASRæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")

    def _init_multimodal_generator(self, jina_api_key, ffmpeg_path):
        """åˆå§‹åŒ–å›¾æ–‡ç¬”è®°ç”Ÿæˆå™¨"""
        if not jina_api_key:
            jina_api_key = os.getenv("JINA_API_KEY")

        logger.info(f"ğŸ”§ æ£€æŸ¥ Jina API Key: {'å·²è®¾ç½®' if jina_api_key else 'æœªè®¾ç½®'}")

        if not jina_api_key:
            logger.warning("âš ï¸  æœªæä¾› Jina API Keyï¼Œå°†è·³è¿‡å›¾æ–‡ç¬”è®°ç”Ÿæˆ")
            return None

        try:
            logger.info("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–å›¾æ–‡ç¬”è®°ç”Ÿæˆå™¨...")
            generator = MultimodalNoteGenerator(
                jina_api_key=jina_api_key,
                ffmpeg_path=ffmpeg_path
            )
            logger.info("âœ… å›¾æ–‡ç¬”è®°ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
            return generator
        except Exception as e:
            logger.error(f"âš ï¸  å›¾æ–‡ç¬”è®°ç”Ÿæˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def extract_audio(self,video_path:str,output_audio:Optional[str]=None)->str:
        """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘ï¼ˆå§”æ‰˜ç»™ffmpeg_processæ¨¡å—ï¼‰"""
        return extract_audio_for_asr(video_path, output_audio, self.ffmpeg_path)
    
    def run_asr(self,audio_path:str,output_json:Optional[str]=None,
               progress_callback=None)->str:
        """è¿è¡ŒASRè½¬å½•ï¼ˆä½¿ç”¨ASRæœåŠ¡æ¨¡å—ï¼‰"""
        if output_json is None:
            output_json=f"{Path(audio_path).stem}_asr.json"

        try:
            if progress_callback:
                return self.asr_service.transcribe_audio_with_progress(
                    audio_path, output_json, progress_callback
                )
            else:
                return self.asr_service.transcribe_audio(audio_path, output_json)
        except Exception as e:
            raise RuntimeError(f"ASRè½¬å½•å¤±è´¥: {e}")
    
    def merge_texts(self,asr_json:str,output_merged:Optional[str]=None,
                   progress_callback=None)->str:
        """åˆå¹¶ASRæ–‡æœ¬"""
        if output_merged is None:
            output_merged=f"{Path(asr_json).stem}_merged.json"

        try:
            if progress_callback:
                success = self.text_merger.process_file_with_progress(
                    asr_json, output_merged, progress_callback
                )
            else:
                success = self.text_merger.process_file(asr_json, output_merged)

            if success:
                logger.info(f"æ–‡æœ¬åˆå¹¶å®Œæˆ: {output_merged}")
                return output_merged
            else:
                raise RuntimeError("æ–‡æœ¬åˆå¹¶å¤±è´¥")
        except Exception as e:
            raise RuntimeError(f"æ–‡æœ¬åˆå¹¶å¤±è´¥: {e}")
    
    def generate_summary(self,merged_json:str,output_summary:Optional[str]=None,
                        progress_callback=None)->str:
        """ç”Ÿæˆæ‘˜è¦"""
        if output_summary is None:
            output_summary=f"{Path(merged_json).stem}_summary.json"

        try:
            if progress_callback:
                success = self.summary_generator.process_file_with_progress(
                    merged_json, output_summary, progress_callback
                )
            else:
                success = self.summary_generator.process_file(merged_json, output_summary)

            if success:
                logger.info(f"æ‘˜è¦ç”Ÿæˆå®Œæˆ: {output_summary}")
                return output_summary
            else:
                raise RuntimeError("æ‘˜è¦ç”Ÿæˆå¤±è´¥")
        except Exception as e:
            raise RuntimeError(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")

    def generate_multimodal_notes(self, video_path:str, summary_json:str, output_dir:str)->Optional[str]:
        """ç”Ÿæˆå›¾æ–‡æ··æ’ç¬”è®°"""
        if not self.enable_multimodal or not self.multimodal_generator:
            logger.warning("âš ï¸  å›¾æ–‡ç¬”è®°ç”ŸæˆåŠŸèƒ½æœªå¯ç”¨æˆ–åˆå§‹åŒ–å¤±è´¥")
            return None

        try:
            notes_dir = os.path.join(output_dir, "multimodal_notes")
            notes_file = self.multimodal_generator.generate_multimodal_notes(
                video_path=video_path,
                summary_json_path=summary_json,
                output_dir=notes_dir
            )
            logger.info(f"å›¾æ–‡ç¬”è®°ç”Ÿæˆå®Œæˆ: {notes_file}")
            return notes_file
        except Exception as e:
            logger.error(f"âš ï¸  å›¾æ–‡ç¬”è®°ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def process_from_existing(self,
                             video_path: str,
                             existing_output_dir: str,
                             start_from: str = "multimodal") -> Dict[str, str]:
        """
        ä»å·²æœ‰çš„è¾“å‡ºç›®å½•ç»§ç»­å¤„ç†

        Args:
            video_path: åŸè§†é¢‘æ–‡ä»¶è·¯å¾„
            existing_output_dir: å·²æœ‰çš„è¾“å‡ºç›®å½•
            start_from: ä»å“ªä¸ªæ­¥éª¤å¼€å§‹

        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        if not os.path.exists(existing_output_dir):
            raise FileNotFoundError(f"è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {existing_output_dir}")

        # æ£€æµ‹å·²æœ‰æ–‡ä»¶
        existing_files = {}
        potential_files = {
            "audio": "audio.wav",
            "asr": "asr_result.json",
            "merged": "merged_text.json",
            "summary": "summary.json"
        }

        for key, filename in potential_files.items():
            file_path = os.path.join(existing_output_dir, filename)
            if os.path.exists(file_path):
                existing_files[key] = file_path
                logger.info(f"âœ… å‘ç°å·²æœ‰æ–‡ä»¶: {key} -> {file_path}")

        if not existing_files:
            raise ValueError(f"åœ¨ç›®å½• {existing_output_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„ä¸­é—´æ–‡ä»¶")

        return self.process_video(
            video_path=video_path,
            output_dir=existing_output_dir,
            start_from=start_from,
            existing_files=existing_files
        )


    def process_video(self,
                     video_path:str,
                     output_dir:Optional[str]=None,
                     keep_temp:bool=False,
                     start_from:str="audio_extract",
                     existing_files:Optional[Dict[str,str]]=None,
                     progress_callback=None)->Dict[str,str]:
        """
        çµæ´»çš„è§†é¢‘å¤„ç†æµç¨‹ï¼Œæ”¯æŒä»ä»»æ„æ­¥éª¤å¼€å§‹

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            keep_temp: æ˜¯å¦ä¿ç•™ä¸´æ—¶æ–‡ä»¶
            start_from: ä»å“ªä¸ªæ­¥éª¤å¼€å§‹ ("audio_extract", "asr", "text_merge", "summary", "multimodal")
            existing_files: å·²å­˜åœ¨çš„æ–‡ä»¶è·¯å¾„å­—å…¸ï¼Œç”¨äºè·³è¿‡å‰é¢çš„æ­¥éª¤
        """
        if output_dir is None:
            output_dir=f"output_{Path(video_path).stem}"

        os.makedirs(output_dir,exist_ok=True)

        logger.info(f"ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        logger.info(f"ğŸš€ ä»æ­¥éª¤å¼€å§‹: {start_from}")

        # åˆå§‹åŒ–æ–‡ä»¶è·¯å¾„ï¼ˆç¡®ä¿ä¸ä¸ºNoneï¼‰
        audio_path = existing_files.get("audio") if existing_files else os.path.join(output_dir,"audio.wav")
        asr_json = existing_files.get("asr") if existing_files else os.path.join(output_dir,"asr_result.json")
        merged_json = existing_files.get("merged") if existing_files else os.path.join(output_dir,"merged_text.json")
        summary_json = existing_files.get("summary") if existing_files else os.path.join(output_dir,"summary.json")

        # å¦‚æœä»existing_filesè·å–çš„è·¯å¾„ä¸ºNoneï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
        if audio_path is None:
            audio_path = os.path.join(output_dir,"audio.wav")
        if asr_json is None:
            asr_json = os.path.join(output_dir,"asr_result.json")
        if merged_json is None:
            merged_json = os.path.join(output_dir,"merged_text.json")
        if summary_json is None:
            summary_json = os.path.join(output_dir,"summary.json")

        multimodal_notes = None

        try:
            # 1. æå–éŸ³é¢‘
            if start_from == "audio_extract":
                logger.info("1ï¸âƒ£ æå–éŸ³é¢‘...")
                audio_path=self.extract_audio(video_path,audio_path)
            elif audio_path and os.path.exists(audio_path):
                logger.info(f"âœ… è·³è¿‡éŸ³é¢‘æå–ï¼Œä½¿ç”¨ç°æœ‰æ–‡ä»¶: {audio_path}")

            # 2. ASRè½¬å½•
            if start_from in ["audio_extract", "asr"]:
                logger.info("2ï¸âƒ£ ASRè½¬å½•...")
                asr_json=self.run_asr(audio_path,asr_json,progress_callback)
            elif asr_json and os.path.exists(asr_json):
                logger.info(f"âœ… è·³è¿‡ASRè½¬å½•ï¼Œä½¿ç”¨ç°æœ‰æ–‡ä»¶: {asr_json}")

            # 3. æ–‡æœ¬åˆå¹¶
            if start_from in ["audio_extract", "asr", "text_merge"]:
                logger.info("3ï¸âƒ£ æ–‡æœ¬åˆå¹¶...")
                merged_json=self.merge_texts(asr_json,merged_json,progress_callback)
            elif merged_json and os.path.exists(merged_json):
                logger.info(f"âœ… è·³è¿‡æ–‡æœ¬åˆå¹¶ï¼Œä½¿ç”¨ç°æœ‰æ–‡ä»¶: {merged_json}")

            # 4. ç”Ÿæˆæ‘˜è¦
            if start_from in ["audio_extract", "asr", "text_merge", "summary"]:
                logger.info("4ï¸âƒ£ ç”Ÿæˆæ‘˜è¦...")
                summary_json=self.generate_summary(merged_json,summary_json,progress_callback)
            elif summary_json and os.path.exists(summary_json):
                logger.info(f"âœ… è·³è¿‡æ‘˜è¦ç”Ÿæˆï¼Œä½¿ç”¨ç°æœ‰æ–‡ä»¶: {summary_json}")
            else:
                # å¦‚æœæ˜¯ä»multimodalå¼€å§‹ï¼Œä½†æ²¡æœ‰summaryæ–‡ä»¶ï¼ŒæŠ¥é”™
                if start_from == "multimodal":
                    raise FileNotFoundError(f"å›¾æ–‡ç¬”è®°ç”Ÿæˆéœ€è¦æ‘˜è¦æ–‡ä»¶ï¼Œä½†æ–‡ä»¶ä¸å­˜åœ¨: {summary_json}")

            # 5. ç”Ÿæˆå›¾æ–‡æ··æ’ç¬”è®°
            if self.enable_multimodal and start_from in ["audio_extract", "asr", "text_merge", "summary", "multimodal"]:
                logger.info("5ï¸âƒ£ ç”Ÿæˆå›¾æ–‡æ··æ’ç¬”è®°...")
                multimodal_notes = self.generate_multimodal_notes(video_path, summary_json, output_dir)

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if not keep_temp:
                try:
                    os.unlink(audio_path)
                    logger.info("ğŸ§¹ æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶")
                except:pass

            result={
                "video_path":video_path,
                "output_dir":output_dir,
                "asr_result":asr_json,
                "merged_text":merged_json,
                "summary":summary_json,
                "multimodal_notes":multimodal_notes
            }
            
            logger.info("âœ… å¤„ç†å®Œæˆï¼")
            logger.info(f"ğŸ“„ ASRç»“æœ: {asr_json}")
            logger.info(f"ğŸ“ åˆå¹¶æ–‡æœ¬: {merged_json}")
            logger.info(f"ğŸ“‹ æ‘˜è¦: {summary_json}")
            if multimodal_notes:
                logger.info(f"ğŸ¨ å›¾æ–‡ç¬”è®°: {multimodal_notes}")

            return result

        except Exception as e:
            logger.error(f"âŒ å¤„ç†å¤±è´¥: {e}")
            raise

# ==================== FastAPI åº”ç”¨ ====================
# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="è§†é¢‘å¤„ç† API",
    description="è§†é¢‘è½¬å½•ã€æ‘˜è¦å’Œå›¾æ–‡ç¬”è®°ç”ŸæˆæœåŠ¡",
    version="1.0.0"
)

@app.get("/")
async def root():
    return {"message": "è§†é¢‘å¤„ç† API æœåŠ¡", "docs": "/docs"}

@app.get("/api/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.post("/api/upload")
async def upload_video(file: UploadFile = File(...)):
    """ä¸Šä¼ è§†é¢‘æ–‡ä»¶"""
    if not file.filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.webm')):
        raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„è§†é¢‘æ ¼å¼")

    # åˆ›å»ºä»»åŠ¡
    task_id = task_manager.create_task(file.filename)
    task_dir = task_manager.get_task_dir(task_id)

    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
    video_path = task_dir / "original_video.mp4"
    with open(video_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    return {
        "task_id": task_id,
        "filename": file.filename,
        "message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸ"
    }

@app.post("/api/process/{task_id}")
async def start_processing(task_id: str, request: ProcessRequest, background_tasks: BackgroundTasks):
    """å¼€å§‹å¤„ç†è§†é¢‘"""
    try:
        metadata = task_manager.load_metadata(task_id)
    except:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    if metadata["status"] != "pending":
        raise HTTPException(status_code=400, detail=f"ä»»åŠ¡çŠ¶æ€é”™è¯¯: {metadata['status']}")

    # å¯åŠ¨åå°å¤„ç†
    background_tasks.add_task(
        process_video_background,
        task_id,
        request.start_from,
        request.enable_multimodal,
        request.keep_temp
    )

    # æ›´æ–°çŠ¶æ€
    task_manager.update_status(task_id, "processing", "starting", 0.1)

    return {"message": "å¤„ç†å·²å¼€å§‹", "task_id": task_id}

@app.get("/api/status/{task_id}")
async def get_task_status(task_id: str):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    try:
        metadata = task_manager.load_metadata(task_id)
        return metadata
    except:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

@app.get("/api/results/{task_id}")
async def get_results(task_id: str):
    """è·å–å¤„ç†ç»“æœ"""
    try:
        metadata = task_manager.load_metadata(task_id)
    except:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    if metadata["status"] != "completed":
        raise HTTPException(status_code=400, detail="ä»»åŠ¡å°šæœªå®Œæˆ")

    task_dir = task_manager.get_task_dir(task_id)
    results = {}

    # æ”¶é›†æ‰€æœ‰ç»“æœæ–‡ä»¶
    result_files = {
        "asr_result": "asr_result.json",
        "merged_text": "merged_text.json",
        "summary": "summary.json",
        "multimodal_notes": "multimodal_notes.json"
    }

    for key, filename in result_files.items():
        file_path = task_dir / filename
        if file_path.exists():
            with open(file_path, "r", encoding="utf-8") as f:
                results[key] = json.load(f)

    return {
        "task_id": task_id,
        "status": metadata["status"],
        "results": results
    }

@app.get("/api/export/{task_id}/markdown")
async def export_markdown(task_id: str):
    """å¯¼å‡º Markdown æ ¼å¼ç¬”è®°"""
    try:
        metadata = task_manager.load_metadata(task_id)
    except:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    if metadata["status"] != "completed":
        raise HTTPException(status_code=400, detail="ä»»åŠ¡å°šæœªå®Œæˆ")

    task_dir = task_manager.get_task_dir(task_id)
    # å›¾æ–‡ç¬”è®°æ–‡ä»¶å¯èƒ½åœ¨ä¸¤ä¸ªä½ç½®ä¹‹ä¸€
    notes_file = task_dir / "multimodal_notes" / "multimodal_notes.json"
    if not notes_file.exists():
        notes_file = task_dir / "multimodal_notes.json"

    if not notes_file.exists():
        raise HTTPException(status_code=404, detail="å›¾æ–‡ç¬”è®°æ–‡ä»¶ä¸å­˜åœ¨")

    # ç”Ÿæˆ Markdown
    generator = MultimodalNoteGenerator(
        jina_api_key=os.getenv("JINA_API_KEY", "dummy")
    )

    markdown_file = task_dir / "notes.md"
    # ä¼ é€’å›¾ç‰‡åŸºç¡€è·¯å¾„ï¼Œç¡®ä¿ç›¸å¯¹è·¯å¾„è®¡ç®—æ­£ç¡®
    generator.export_to_markdown(
        notes_json_path=str(notes_file),
        output_path=str(markdown_file),
        image_base_path=str(task_dir)
    )

    return FileResponse(
        path=str(markdown_file),
        filename=f"video_notes_{task_id}.md",
        media_type="text/markdown"
    )


@app.get("/api/export/{task_id}/json")
async def export_json(task_id: str):
    """å¯¼å‡ºåŸå§‹ JSON æ ¼å¼ç¬”è®°"""
    try:
        metadata = task_manager.load_metadata(task_id)
    except:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    if metadata["status"] != "completed":
        raise HTTPException(status_code=400, detail="ä»»åŠ¡å°šæœªå®Œæˆ")

    task_dir = task_manager.get_task_dir(task_id)
    # å›¾æ–‡ç¬”è®°æ–‡ä»¶å¯èƒ½åœ¨ä¸¤ä¸ªä½ç½®ä¹‹ä¸€
    notes_file = task_dir / "multimodal_notes" / "multimodal_notes.json"
    if not notes_file.exists():
        notes_file = task_dir / "multimodal_notes.json"

    if not notes_file.exists():
        raise HTTPException(status_code=404, detail="å›¾æ–‡ç¬”è®°æ–‡ä»¶ä¸å­˜åœ¨")

    return FileResponse(
        path=str(notes_file),
        filename=f"video_notes_{task_id}.json",
        media_type="application/json"
    )


# å…¨å±€ä»»åŠ¡ç®¡ç†å™¨
task_manager = TaskManager()


async def process_video_background(task_id: str, start_from: str, enable_multimodal: bool, keep_temp: bool):
    """åå°å¤„ç†è§†é¢‘çš„å‡½æ•°"""
    try:
        task_dir = task_manager.get_task_dir(task_id)
        video_path = task_dir / "original_video.mp4"

        # åˆ›å»ºå·¥ä½œæµå®ä¾‹
        workflow = VideoProcessingWorkflow(enable_multimodal=enable_multimodal)

        # æ›´æ–°è¿›åº¦å›è°ƒ
        def update_progress(step: str, progress: float):
            logger.info(f"ğŸ”„ è¿›åº¦æ›´æ–°: {step} - {progress:.1%}")
            task_manager.update_status(task_id, "processing", step, progress)

        # æ‰§è¡Œå¤„ç†
        result = workflow.process_video(
            video_path=str(video_path),
            output_dir=str(task_dir),
            keep_temp=keep_temp,
            start_from=start_from,
            progress_callback=update_progress
        )

        # å¤„ç†å®Œæˆ
        task_manager.update_status(task_id, "completed", "finished", 1.0)

    except Exception as e:
        # å¤„ç†å¤±è´¥
        task_manager.update_status(task_id, "failed", error_message=str(e))

# å¯åŠ¨æœåŠ¡å™¨çš„ä»£ç 
if __name__ == "__main__":
    import uvicorn

    # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
    storage_dir = Path("storage")
    storage_dir.mkdir(exist_ok=True)

    logger.info("ğŸš€ å¯åŠ¨è§†é¢‘å¤„ç† API æœåŠ¡...")
    logger.info(f"ğŸ“ å­˜å‚¨ç›®å½•: {storage_dir.absolute()}")
    logger.info("ğŸŒ API æ–‡æ¡£: http://localhost:8000/docs")
    logger.info("ğŸ” å¥åº·æ£€æŸ¥: http://localhost:8000/api/health")
    logger.info("ğŸ“¤ ä¸Šä¼ æ¥å£: http://localhost:8000/api/upload")

    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
